{"name":"brí-focal","tagline":"Joint embedding of words and relationships in semantic space.","body":"## Intro-level explanation (for non-experts)\r\n\r\nSuppose we have a set of _things_, like words in a language, concepts in an ontology, or any other collection of objects. To reason computationally about these things/entities, or use them in modelling tasks we require a representation; a way of encoding them which is meaningful to a computer. A naïve approach might be to number all the entities, so 'aardvark' is 1 and 'zoetrope' is 140,181, but it's not very useful, and may be confusing. In this example entities are ordered alphabetically, but do we really want 'dog' to be closer to 'donkey' than to 'puppy'? Another approach is to make all entities equidistant from each other, which might make sense if we know nothing about them: should 'gabhar' be closer to 'gadhar' than 'caora'? However, this ignores the (possibly unknown) structure existing between these entities. In a good representation, _similar_ entities should have _similar representations_.\r\n\r\nThe question is now: how do we know which entities are _similar_ (without asking humans)? For language, a common approach is called **distributional semantics**. The idea (from Firth) is that a 'word is characterised by the company it keeps'; look at the sentences a word appears in, and you'll learn something about its meaning. If two words are completely interchangeable in a sentence, they're probably synonyms. So, choose a representation so that words appearing in similar contexts (within a sentence) have similar representations. If this seems circular, it's because it is, a little. Before we can say how similar a _context_ is, we need the similarity of the _words_ in that context. The way we overcome this is to start with a guess: make up a representation for each word - you can think of this as some location on a map, although in practice it's much higher dimensional - and update them as you see more sentences. Eventually, if all goes well, similar words end up clustered together.\r\n\r\nThis is great! Now when we look at the representation of 'dog', it's close to 'puppy' and 'doggy' and 'doge' and a little close to 'cat' and 'wolf', not so close to 'horse' and very far from 'sadness'. We can pass these representations into an algorithm to do something else - say, to identify which tweets are about dogs (a noble and important task), and it will 'know' that a person mentioning puppies might be talking about dogs, even if they didn't use that word. That's _one_ of the benefits of having a good representation.\r\n\r\nThe work, however, is not yet complete. Consider the following:\r\n\r\n- when I said _similar_, what exactly did I mean?\r\n- what happens if we just don't have that many sentences?\r\n\r\n### Notions of similarity\r\n\r\nWithout further qualification, humans are capable of making vague similarity judgements: you probably agreed that dogs are more like puppies than they are donkeys, but now suppose we're shepherds looking for an animal to guard the flock. In this _specific context_ (that of sheep-guarding), dogs are more like donkeys than puppies (donkeys can be employed to guard livestock, puppies should not). At the same time, puppies and kittens are both _young animals_, so while searching for cute gifs, either might do. We want a representation which knows about these different _types_ of similarity.\r\n\r\n### Data limitations\r\n\r\nExamples of English are very abundant on the internet. Google is especially good at [describing the statistics of English](https://books.google.com/ngrams), which means we can get a very accurate idea of the _typical context_ for any given word. In other languages and domains, this may not be the case. My focus is on medicine, where the following things occur:\r\n\r\n1. text contains private information about patients, and is not publicly available\r\n2. doctors do not write eloquent, diverse and nuanced sentences: doctors are _terse_\r\n\r\nSo we have limited access to data which may not contain all the information we need. The danger of point 2 is that our idea of a word's context becomes quite coarse. We might know that _tamoxifen_ and _imatinib_ are both drugs, because we see many sentences like 'started on tamoxifen/imatinib' (note that this is a sentence fragment) and have figured out that one 'starts on' drugs, but the fact that these drugs treat entirely different cancers may be lost. This is a problem.\r\n\r\n### Solutions and this project\r\n\r\nIn this project we came up with a model which can be used to learn representations which know about _different notions of similarity_, and which can still work even if _data is limited_. \r\n\r\nWe did this by extending the notion of 'company' as used by Firth; a word can keep many kinds of company: its neighbours in a sentence _as well as_ any other words with which it has some relationship. Dogs can guard sheep, and so can donkeys, so in the context of 'guarding', they may as well be neighbours. We can then augment our dataset with statements of the form 'X is related to Y through Z' (if they exist!) to provide additional information to _both_:\r\n\r\n1. provide more information to better tune the representation - knowing that tamoxifen treats breast cancer and imatinib treats liver cancer means the representation should _not_ treat them as synonyms\r\n2. allow us to explicitly handle the different _types_ of similarity, as captured by the types of relationships Z entities can participate in, and with whom\r\n\r\nLuckily, technical domains such as medicine tend towards categorising their knowledge in structured databases, which provides us a source of 'X is related to Y through Z' statements! (This is not a coincidence.) And as a side-effect of training our representation on such a dataset, we can actually try to _extend_ it. Since we learn a general representation for words regardless of their _source_ (sentences v. relationship statements), we can try to apply what we learned about the _relationships_ to words apearing only in the sentences. That is, if 'gleevec' never appeared in a 'X is related to Y'-type statement, but we learned that gleevec is a synoynm for imatinib, then we can say with some confidence that 'gleevec is related to leukaemia through \"treats\"'.\r\n\r\n![](https://corcra.github.io/assets/illu.png)\r\n\r\n## Advanced-level explanation\r\n\r\nWe are motivated by the idea that _relationships_ between entities in a semantic space can be modelled by _geometric transformations_ of that space. This provides structure on the solution space which should produce more semantically meaningful representations, as well as enabling knowledge discovery by exploiting the learned transformations.\r\n\r\nSpecifically, we learn a joint generative model over (**S**, **R**, **T**) triples, where **S** and **T** are tokens (e.g. words in a vocabulary) and **R** is a possible relationship between them. Each **S** and **T** receives a vector representation, while **R** is an affine transformation of the vector space. True triples, corresponding to statements \"**S** is related to **T** through **R**\" have low energy, meaning the cosine distance between the **T** vector and the _**R**-transformed_ **C** vector must be low. We relate this to probability using a Boltzmann distribution given this energy function, and learn the set of parameters (all vectors and transformation matrices) using stochastic maximum likelihood. We approximate gradients of the partition function using persistent contrastive divergence, obtaining model samples with Gibbs sampling from the conditional distributions for each element of the triple. Our model can further handle missing labels, such as statements like \"S is related to T through some unknown relationship\" by averaging weighted gradients according to the conditional probability of each possible label.\r\n\r\nFor more details, please consult [the paper](http://arxiv.org/abs/1510.00259)!\r\n\r\n## Code\r\n\r\n[Implementation](https://github.com/corcra/bf2) is in Python, please direct questions or issues to @corcra!\r\n\r\n## Publications\r\n\r\n- [A Generative Model of Words and Relationships from Multiple Sources](http://arxiv.org/abs/1510.00259) - Stephanie L. Hyland, Theofanis Karaletsos, Gunnar Rätsch; to appear in Proceedings of the [Thirtieth AAAI Conference on Artificial Intelligence 2016](https://www.aaai.org/Conferences/AAAI/aaai16.php)\r\n- [Knowledge Transfer with Medical Language Embeddings](http://arxiv.org/abs/1602.03551) - Stephanie L. Hyland, Theofanis Karaletsos, Gunnar Rätsch; to appear at the [Fifth Workshop on Data Mining for Medicine and Healthcare](http://www.dmmh.org/sdm16) at the 16th SIAM International Conference on Data Mining (SDM 2016)","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}